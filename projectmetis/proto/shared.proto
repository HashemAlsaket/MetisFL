syntax = "proto3";

package projectmetis;

import "google/protobuf/timestamp.proto";
import "projectmetis/proto/optimizers.proto";

// Acknowledgment message.
message Ack {
  // Set to true if this acknowledges the successful completion of a request, or
  // false otherwise.
  bool status = 1;

  // Timestamp of the acknowledgement.
  google.protobuf.Timestamp timestamp = 2;

  // An optional message.
  string message = 3;
}

// A server entity that participates in the collaborative learning environment.
message ServerEntity {
  // Either the hostname or the IP address of the server.
  string hostname = 1;

  // The server port that the service is running on.
  uint32 port = 2;
}

message DatasetSpec {
  uint32 num_training_examples = 1;
  uint32 num_validation_examples = 2;
  uint32 num_test_examples = 3;

  message ClassificationDatasetSpec {
    map<uint32, uint32> class_examples_num = 1;
  }

  message RegressionDatasetSpec {
    // TODO (canast02) Need to add histogram support; the following statistics should refer to a histogram bucket.
    double min = 1;
    double max = 2;
    double mean = 3;
    double median = 4;
    double mode = 5;
    double stddev = 6;
  }

  oneof specs {
    ClassificationDatasetSpec classification_spec = 4;
    RegressionDatasetSpec regression_spec = 5;
  }
}

message LearningTask {
  // This reflects the number of local steps the learner needs to perform.
  // It is similar to epochs if we take |num_training_examples| / batch_size.
  uint32 num_local_updates = 1;

  float training_dataset_percentage_for_stratified_validation = 2;

  // TODO We need to define the metrics we expect the learner to return. This
  //  should be similar to the evaluation field in message `learner.EvaluateModelRequest`.
}

message EpochEvaluation {
  uint32 epoch_id = 1; // The id of the epoch. This is an integer-incremental value (i.e., serial number). A learner is training continuously and therefore it can increment its epoch id as it progresses its training.
  float epoch_score = 2; // The associated score of the epoch. This could be any numeric value, such as accuracy and f1-score in classification and MSE in regression tasks.
}

message LearnerExecutionBaseMetadata {
  // TODO For every training, validation and test score below, we need to define the metrics we expect the learner to return. These metrics should be the ones defined in the evaluation field of message `common.LearningTask.evaluation`.
  repeated EpochEvaluation epochs_training_scores = 1; // A list with all training evaluations across all epochs.
  repeated EpochEvaluation epochs_validation_scores = 2; // A list with all validation evaluations across all epochs.
  repeated EpochEvaluation epochs_test_scores = 3; // A list of all test evaluations across all epochs.
  float completed_epochs = 4; // Learner may perform partial epochs, thus the float data type.
  uint32 completed_batches = 5;
  uint32 batch_size = 6;
  float processing_ms_per_epoch = 7; // Time-per-epoch in milliseconds.
  float processing_ms_per_batch = 8; // Time-per-batch in milliseconds.
}

message LearningHyperParameters {
  uint32 batch_size = 1;
  oneof optimizer {
    VanillaSGD vanilla_sgd = 3;
    MomentumSGD momentum_sgd = 4;
    FedProx fed_prox = 5;
    Adam adam = 6;
  }
  // TODO We defined this message as LearningHyperparameters because we expect to extend its definition with additional fields related to model training.
}
